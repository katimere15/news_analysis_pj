{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as wb\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/jprthrkx73n0d9pl0mgr0kqm0000gn/T/ipykernel_82322/2642073490.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Price'][i] = 0\n",
      "/var/folders/3h/jprthrkx73n0d9pl0mgr0kqm0000gn/T/ipykernel_82322/2642073490.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Price'][i] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>최고가</th>\n",
       "      <th>최저가</th>\n",
       "      <th>시작가</th>\n",
       "      <th>종가</th>\n",
       "      <th>거래량</th>\n",
       "      <th>등락</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>2032.229980</td>\n",
       "      <td>2009.329956</td>\n",
       "      <td>2015.089966</td>\n",
       "      <td>2017.339966</td>\n",
       "      <td>461700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-02</th>\n",
       "      <td>2005.310059</td>\n",
       "      <td>1987.119995</td>\n",
       "      <td>1995.310059</td>\n",
       "      <td>1998.130005</td>\n",
       "      <td>438500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-05</th>\n",
       "      <td>1987.640015</td>\n",
       "      <td>1945.390015</td>\n",
       "      <td>1985.930054</td>\n",
       "      <td>1946.979980</td>\n",
       "      <td>639600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>1948.530029</td>\n",
       "      <td>1891.810059</td>\n",
       "      <td>1900.359985</td>\n",
       "      <td>1917.500000</td>\n",
       "      <td>739600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-07</th>\n",
       "      <td>1929.290039</td>\n",
       "      <td>1901.609985</td>\n",
       "      <td>1925.329956</td>\n",
       "      <td>1909.709961</td>\n",
       "      <td>760800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-26</th>\n",
       "      <td>2415.389893</td>\n",
       "      <td>2395.169922</td>\n",
       "      <td>2397.270020</td>\n",
       "      <td>2412.959961</td>\n",
       "      <td>415100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>2415.530029</td>\n",
       "      <td>2396.189941</td>\n",
       "      <td>2412.520020</td>\n",
       "      <td>2415.530029</td>\n",
       "      <td>333400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-28</th>\n",
       "      <td>2443.429932</td>\n",
       "      <td>2429.070068</td>\n",
       "      <td>2437.570068</td>\n",
       "      <td>2435.270020</td>\n",
       "      <td>490900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-29</th>\n",
       "      <td>2463.050049</td>\n",
       "      <td>2442.010010</td>\n",
       "      <td>2453.530029</td>\n",
       "      <td>2451.500000</td>\n",
       "      <td>499000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>2461.399902</td>\n",
       "      <td>2437.129883</td>\n",
       "      <td>2444.050049</td>\n",
       "      <td>2452.250000</td>\n",
       "      <td>487000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    최고가          최저가          시작가           종가     거래량  등락\n",
       "Date                                                                      \n",
       "2019-08-01  2032.229980  2009.329956  2015.089966  2017.339966  461700   0\n",
       "2019-08-02  2005.310059  1987.119995  1995.310059  1998.130005  438500   0\n",
       "2019-08-05  1987.640015  1945.390015  1985.930054  1946.979980  639600   0\n",
       "2019-08-06  1948.530029  1891.810059  1900.359985  1917.500000  739600   0\n",
       "2019-08-07  1929.290039  1901.609985  1925.329956  1909.709961  760800   1\n",
       "...                 ...          ...          ...          ...     ...  ..\n",
       "2022-07-26  2415.389893  2395.169922  2397.270020  2412.959961  415100   1\n",
       "2022-07-27  2415.530029  2396.189941  2412.520020  2415.530029  333400   1\n",
       "2022-07-28  2443.429932  2429.070068  2437.570068  2435.270020  490900   1\n",
       "2022-07-29  2463.050049  2442.010010  2453.530029  2451.500000  499000   1\n",
       "2022-08-01  2461.399902  2437.129883  2444.050049  2452.250000  487000   0\n",
       "\n",
       "[739 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 코스피지수 크롤링\n",
    "#약 3년치 데이터를 크롤링해 옴\n",
    "start = datetime.datetime(2019, 8, 1)\n",
    "end = datetime.datetime(2022, 8, 1)\n",
    "\n",
    "# ^KS11 : 코스피\n",
    "df_null = wb.DataReader(\"^KS11\",\"yahoo\",start,end)\n",
    "\n",
    "# 결측치 제거\n",
    "df = df_null.dropna()\n",
    "\n",
    "# Close와 Adj Close는 중복되는 columns인것을 확인 함\n",
    "# Adj Close열을 제거\n",
    "df.drop([\"Adj Close\"],axis=1, inplace=True)\n",
    "\n",
    "# 새로운 칼럼 생성\n",
    "# (Price : 당일 대비 다음날 주가가 상승했으면 1, 하락했으면 0 표시)\n",
    "df['Price'] = 0\n",
    "for i in range(len(df)-1):\n",
    "    if df['Close'][i] < df['Close'][i+1]:\n",
    "        df['Price'][i] = 1\n",
    "    else:\n",
    "        df['Price'][i] = 0\n",
    "\n",
    "# columns명을 알기 쉽게 한글로 변경\n",
    "df.columns = [\"최고가\", \"최저가\" , \"시작가\", \"종가\", \"거래량\" , \"등락\"]\n",
    "\n",
    "# 파일 저장\n",
    "df.to_csv('kospi_주가데이터.csv',encoding='utf-8-sig')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20190807',\n",
       " '20190808',\n",
       " '20190809',\n",
       " '20190813',\n",
       " '20190816',\n",
       " '20190819',\n",
       " '20190820',\n",
       " '20190826',\n",
       " '20190827',\n",
       " '20190829',\n",
       " '20190830',\n",
       " '20190903',\n",
       " '20190904',\n",
       " '20190905',\n",
       " '20190906',\n",
       " '20190909',\n",
       " '20190910',\n",
       " '20190911',\n",
       " '20190916',\n",
       " '20190917',\n",
       " '20190918',\n",
       " '20190919',\n",
       " '20190920',\n",
       " '20190923',\n",
       " '20190925',\n",
       " '20190927',\n",
       " '20190930',\n",
       " '20191004',\n",
       " '20191007',\n",
       " '20191010',\n",
       " '20191011',\n",
       " '20191014',\n",
       " '20191015',\n",
       " '20191018',\n",
       " '20191021',\n",
       " '20191023',\n",
       " '20191024',\n",
       " '20191025',\n",
       " '20191030',\n",
       " '20191031',\n",
       " '20191101',\n",
       " '20191104',\n",
       " '20191105',\n",
       " '20191106',\n",
       " '20191111',\n",
       " '20191113',\n",
       " '20191114',\n",
       " '20191121',\n",
       " '20191122',\n",
       " '20191126',\n",
       " '20191129',\n",
       " '20191205',\n",
       " '20191206',\n",
       " '20191209',\n",
       " '20191210',\n",
       " '20191211',\n",
       " '20191212',\n",
       " '20191216',\n",
       " '20191218',\n",
       " '20191219',\n",
       " '20191224',\n",
       " '20191226',\n",
       " '20200102',\n",
       " '20200106',\n",
       " '20200108',\n",
       " '20200109',\n",
       " '20200110',\n",
       " '20200113',\n",
       " '20200115',\n",
       " '20200116',\n",
       " '20200117',\n",
       " '20200121',\n",
       " '20200128',\n",
       " '20200203',\n",
       " '20200204',\n",
       " '20200205',\n",
       " '20200210',\n",
       " '20200211',\n",
       " '20200213',\n",
       " '20200218',\n",
       " '20200224',\n",
       " '20200228',\n",
       " '20200302',\n",
       " '20200303',\n",
       " '20200304',\n",
       " '20200309',\n",
       " '20200319',\n",
       " '20200323',\n",
       " '20200324',\n",
       " '20200326',\n",
       " '20200330',\n",
       " '20200401',\n",
       " '20200402',\n",
       " '20200403',\n",
       " '20200406',\n",
       " '20200408',\n",
       " '20200409',\n",
       " '20200413',\n",
       " '20200416',\n",
       " '20200421',\n",
       " '20200422',\n",
       " '20200424',\n",
       " '20200427',\n",
       " '20200428',\n",
       " '20200504',\n",
       " '20200507',\n",
       " '20200512',\n",
       " '20200514',\n",
       " '20200515',\n",
       " '20200518',\n",
       " '20200519',\n",
       " '20200520',\n",
       " '20200522',\n",
       " '20200525',\n",
       " '20200526',\n",
       " '20200528',\n",
       " '20200529',\n",
       " '20200601',\n",
       " '20200602',\n",
       " '20200603',\n",
       " '20200604',\n",
       " '20200605',\n",
       " '20200608',\n",
       " '20200609',\n",
       " '20200615',\n",
       " '20200616',\n",
       " '20200618',\n",
       " '20200622',\n",
       " '20200623',\n",
       " '20200625',\n",
       " '20200629',\n",
       " '20200701',\n",
       " '20200702',\n",
       " '20200703',\n",
       " '20200708',\n",
       " '20200710',\n",
       " '20200714',\n",
       " '20200716',\n",
       " '20200720',\n",
       " '20200724',\n",
       " '20200727',\n",
       " '20200728',\n",
       " '20200729',\n",
       " '20200731',\n",
       " '20200803',\n",
       " '20200804',\n",
       " '20200805',\n",
       " '20200806',\n",
       " '20200807',\n",
       " '20200810',\n",
       " '20200811',\n",
       " '20200812',\n",
       " '20200818',\n",
       " '20200820',\n",
       " '20200821',\n",
       " '20200824',\n",
       " '20200825',\n",
       " '20200827',\n",
       " '20200831',\n",
       " '20200901',\n",
       " '20200902',\n",
       " '20200904',\n",
       " '20200907',\n",
       " '20200909',\n",
       " '20200910',\n",
       " '20200911',\n",
       " '20200914',\n",
       " '20200917',\n",
       " '20200922',\n",
       " '20200924',\n",
       " '20200925',\n",
       " '20200928',\n",
       " '20200929',\n",
       " '20201005',\n",
       " '20201006',\n",
       " '20201007',\n",
       " '20201008',\n",
       " '20201016',\n",
       " '20201019',\n",
       " '20201020',\n",
       " '20201022',\n",
       " '20201027',\n",
       " '20201030',\n",
       " '20201102',\n",
       " '20201103',\n",
       " '20201104',\n",
       " '20201105',\n",
       " '20201106',\n",
       " '20201109',\n",
       " '20201110',\n",
       " '20201112',\n",
       " '20201113',\n",
       " '20201117',\n",
       " '20201118',\n",
       " '20201119',\n",
       " '20201120',\n",
       " '20201123',\n",
       " '20201125',\n",
       " '20201126',\n",
       " '20201130',\n",
       " '20201201',\n",
       " '20201202',\n",
       " '20201203',\n",
       " '20201204',\n",
       " '20201208',\n",
       " '20201210',\n",
       " '20201215',\n",
       " '20201217',\n",
       " '20201218',\n",
       " '20201222',\n",
       " '20201223',\n",
       " '20201224',\n",
       " '20201228',\n",
       " '20201229',\n",
       " '20201230',\n",
       " '20210104',\n",
       " '20210106',\n",
       " '20210107',\n",
       " '20210112',\n",
       " '20210113',\n",
       " '20210118',\n",
       " '20210119',\n",
       " '20210120',\n",
       " '20210122',\n",
       " '20210129',\n",
       " '20210201',\n",
       " '20210202',\n",
       " '20210204',\n",
       " '20210209',\n",
       " '20210210',\n",
       " '20210215',\n",
       " '20210218',\n",
       " '20210224',\n",
       " '20210226',\n",
       " '20210302',\n",
       " '20210310',\n",
       " '20210311',\n",
       " '20210315',\n",
       " '20210317',\n",
       " '20210324',\n",
       " '20210325',\n",
       " '20210329',\n",
       " '20210331',\n",
       " '20210401',\n",
       " '20210402',\n",
       " '20210405',\n",
       " '20210406',\n",
       " '20210407',\n",
       " '20210409',\n",
       " '20210412',\n",
       " '20210413',\n",
       " '20210414',\n",
       " '20210415',\n",
       " '20210416',\n",
       " '20210419',\n",
       " '20210421',\n",
       " '20210422',\n",
       " '20210423',\n",
       " '20210503',\n",
       " '20210504',\n",
       " '20210506',\n",
       " '20210507',\n",
       " '20210513',\n",
       " '20210517',\n",
       " '20210524',\n",
       " '20210527',\n",
       " '20210528',\n",
       " '20210531',\n",
       " '20210601',\n",
       " '20210602',\n",
       " '20210604',\n",
       " '20210609',\n",
       " '20210610',\n",
       " '20210611',\n",
       " '20210614',\n",
       " '20210615',\n",
       " '20210617',\n",
       " '20210621',\n",
       " '20210622',\n",
       " '20210623',\n",
       " '20210624',\n",
       " '20210629',\n",
       " '20210702',\n",
       " '20210705',\n",
       " '20210709',\n",
       " '20210712',\n",
       " '20210714',\n",
       " '20210721',\n",
       " '20210722',\n",
       " '20210726',\n",
       " '20210727',\n",
       " '20210728',\n",
       " '20210730',\n",
       " '20210802',\n",
       " '20210803',\n",
       " '20210817',\n",
       " '20210820',\n",
       " '20210823',\n",
       " '20210824',\n",
       " '20210826',\n",
       " '20210827',\n",
       " '20210830',\n",
       " '20210831',\n",
       " '20210902',\n",
       " '20210903',\n",
       " '20210909',\n",
       " '20210910',\n",
       " '20210913',\n",
       " '20210914',\n",
       " '20210916',\n",
       " '20210924',\n",
       " '20210929',\n",
       " '20211006',\n",
       " '20211012',\n",
       " '20211013',\n",
       " '20211014',\n",
       " '20211018',\n",
       " '20211022',\n",
       " '20211025',\n",
       " '20211029',\n",
       " '20211101',\n",
       " '20211103',\n",
       " '20211108',\n",
       " '20211111',\n",
       " '20211112',\n",
       " '20211118',\n",
       " '20211119',\n",
       " '20211130',\n",
       " '20211201',\n",
       " '20211202',\n",
       " '20211203',\n",
       " '20211206',\n",
       " '20211207',\n",
       " '20211208',\n",
       " '20211214',\n",
       " '20211215',\n",
       " '20211216',\n",
       " '20211220',\n",
       " '20211221',\n",
       " '20211222',\n",
       " '20211223',\n",
       " '20211227',\n",
       " '20211230',\n",
       " '20220106',\n",
       " '20220110',\n",
       " '20220111',\n",
       " '20220119',\n",
       " '20220127',\n",
       " '20220128',\n",
       " '20220203',\n",
       " '20220207',\n",
       " '20220208',\n",
       " '20220209',\n",
       " '20220215',\n",
       " '20220216',\n",
       " '20220217',\n",
       " '20220222',\n",
       " '20220224',\n",
       " '20220225',\n",
       " '20220228',\n",
       " '20220302',\n",
       " '20220308',\n",
       " '20220315',\n",
       " '20220316',\n",
       " '20220317',\n",
       " '20220321',\n",
       " '20220322',\n",
       " '20220324',\n",
       " '20220328',\n",
       " '20220329',\n",
       " '20220330',\n",
       " '20220401',\n",
       " '20220404',\n",
       " '20220407',\n",
       " '20220412',\n",
       " '20220413',\n",
       " '20220418',\n",
       " '20220420',\n",
       " '20220425',\n",
       " '20220427',\n",
       " '20220428',\n",
       " '20220512',\n",
       " '20220516',\n",
       " '20220517',\n",
       " '20220519',\n",
       " '20220520',\n",
       " '20220524',\n",
       " '20220526',\n",
       " '20220527',\n",
       " '20220530',\n",
       " '20220602',\n",
       " '20220615',\n",
       " '20220620',\n",
       " '20220623',\n",
       " '20220624',\n",
       " '20220627',\n",
       " '20220704',\n",
       " '20220706',\n",
       " '20220707',\n",
       " '20220712',\n",
       " '20220714',\n",
       " '20220715',\n",
       " '20220719',\n",
       " '20220720',\n",
       " '20220722',\n",
       " '20220725',\n",
       " '20220726',\n",
       " '20220727',\n",
       " '20220728',\n",
       " '20220729']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 등락 값이 \"0\"인 데이터와 \"1\"인 데이터를 나눠서 리스트화\n",
    "# 여기서 리스트화 하는 이유는 다음날 주가가 하락한 경우의 뉴스 타이틀과 상승한 뉴스타이틀을 크롤링해 분류하기 위함\n",
    "price_data = pd.read_csv('kospi_주가데이터.csv')\n",
    "\n",
    "#주가가 하락한 경우의 Date 데이터 리스트 date_0\n",
    "df_0 = price_data[price_data['등락']==0]['Date']\n",
    "date_0 = []\n",
    "for i in range(0,len(df_0)):\n",
    "    date_0.append(str(df_0.tolist()[i])[:10].replace('-',''))\n",
    "\n",
    "#주가가 상승한 경우의 Date 데이터 리스트 date_1\n",
    "df_1 = price_data[price_data['등락']==1]['Date']\n",
    "date_1 = []\n",
    "for i in range(0,len(df_1)):\n",
    "    date_1.append(str(df_1.tolist()[i])[:10].replace('-',''))\n",
    "\n",
    "date_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#뉴스타이틀 크롤링을 위한 모듈 import\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 팍스넷 크롤링 함수 paxnet_news_title\n",
    "result_list = []\n",
    "error_cnt = 0\n",
    "\n",
    "def paxnet_news_title(dates):\n",
    "    base_url = 'http://www.paxnet.co.kr/news/much?newsSetId=4667&currentPageNo={}&genDate={}&objId=N4667'\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    for date in dates:\n",
    "        for page in range(1, 3):\n",
    "            url = base_url.format(page, date)\n",
    "            res = requests.get(url, headers=headers)\n",
    "            if res.status_code == 200:\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                title_list = soup.select('ul.thumb-list li')\n",
    "                for title in title_list:\n",
    "                    try:\n",
    "                        news_title = title.select_one('dl.text > dt').text.strip()\n",
    "                        #\"[문자]\" 가 붙은 제거\n",
    "                        #find 함수는 문자열안에 지정한 문자가 있을경우 그 위치(index)를 int로 반환해준다.\n",
    "                        #지정한 문자를 찾지 못할 경우 -1 을 반환 \n",
    "                        find_1=news_title.find(\"[\")\n",
    "                        find_2=news_title.find(\"]\")\n",
    "\n",
    "                        # find함수의 결과가 -1가 아닌 경우(문자열안에 \"[문자]\"가 있다.)\n",
    "                        # 그 위치를 찾아 제거하고 result_list에 추가\n",
    "                        if find_1 != -1:\n",
    "                            slice_news_title=news_title[find_1:find_2+1]\n",
    "                            result_list.append([news_title.strip(slice_news_title).strip()])\n",
    "                        #find함수의 결과가 -1 일경우(문자열안에 \"[문자]\"가 없다.)\n",
    "                        #바로 result_list에 추가\n",
    "                        elif find_1 == -1:\n",
    "                            result_list.append([news_title])\n",
    "                    except:\n",
    "                        error_cnt += 1\n",
    "paxnet_news_title(date_0)\n",
    "title_df_0 = pd.DataFrame(result_list, columns=['뉴스제목'])\n",
    "title_df_0['주가변동'] = 0\n",
    "result_list = []\n",
    "\n",
    "paxnet_news_title(date_1)\n",
    "title_df_1 = pd.DataFrame(result_list, columns=['뉴스제목'])\n",
    "title_df_1['주가변동'] = 1\n",
    "result_list = []\n",
    "\n",
    "\n",
    "\n",
    "#팍스넷 크롤링 데이터 합쳐 csv파일로 만들기\n",
    "title_df = pd.concat([title_df_0, title_df_1])\n",
    "#중복 데이터 삭제 \n",
    "del_title_df = title_df.drop_duplicates(['뉴스제목'])\n",
    "#데이터프레임 저장 \n",
    "del_title_df.to_csv('팍스넷_뉴스타이틀.csv', index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>뉴스제목</th>\n",
       "      <th>주가변동</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>초반 상승세…기업 실적에 다시 관심</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>日 화이트리스트 제외?…코스피 2000선 무너지나</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>美 FOMC에 日 수출규제까지…원화가치 급락</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>美 금리인하에도 시장은 '실망'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>코스피, '日 화이트리스트 제외' 앞두고 하락…7개월 만에 최저치</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12650</th>\n",
       "      <td>美증시 상승에 코스피 강세…2450선 출발</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12651</th>\n",
       "      <td>美경기 부진, 긴축 속도조절론↑…환율, 1290원대 이틀째 하락 예상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>GDP '연속 마이너스'에도 美증시↑...\"거의 다 왔다\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12653</th>\n",
       "      <td>미국 두 분기 연속 역성장 반긴 뉴욕증시…전국 찜통더위 계속</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12654</th>\n",
       "      <td>국내 채권형 펀드, 2737억원 순유입</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22732 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         뉴스제목  주가변동\n",
       "0                         초반 상승세…기업 실적에 다시 관심     0\n",
       "1                 日 화이트리스트 제외?…코스피 2000선 무너지나     0\n",
       "2                    美 FOMC에 日 수출규제까지…원화가치 급락     0\n",
       "3                           美 금리인하에도 시장은 '실망'     0\n",
       "4        코스피, '日 화이트리스트 제외' 앞두고 하락…7개월 만에 최저치     0\n",
       "...                                       ...   ...\n",
       "12650                 美증시 상승에 코스피 강세…2450선 출발     1\n",
       "12651  美경기 부진, 긴축 속도조절론↑…환율, 1290원대 이틀째 하락 예상     1\n",
       "12652        GDP '연속 마이너스'에도 美증시↑...\"거의 다 왔다\"     1\n",
       "12653       미국 두 분기 연속 역성장 반긴 뉴욕증시…전국 찜통더위 계속     1\n",
       "12654                   국내 채권형 펀드, 2737억원 순유입     1\n",
       "\n",
       "[22732 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네이버 크롤링 함수 naver_news_title\n",
    "result_list = []\n",
    "error_cnt = 0\n",
    "def naver_news_title(dates):\n",
    "    base_url = 'https://finance.naver.com/news/mainnews.naver?date={}&page={}'\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'\n",
    "    }\n",
    "    for date in dates:\n",
    "        for page in range(1, 3):\n",
    "            url = base_url.format(date,page)\n",
    "            res = requests.get(url, headers=headers)\n",
    "            if res.status_code == 200:\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                title_list = soup.select('#contentarea_left > div.mainNewsList > ul > li > dl')\n",
    "                for title in title_list:\n",
    "                    try:\n",
    "                        news_title = title.select_one('.articleSubject').text.strip()\n",
    "                        find_1=news_title.find(\"[\")\n",
    "                        find_2=news_title.find(\"]\")\n",
    "                        if find_1 != -1:\n",
    "                            slice_news_title=news_title[find_1:find_2+1]\n",
    "                            news_title.strip(slice_news_title)\n",
    "                            result_list.append([news_title.strip(slice_news_title).strip()])\n",
    "                        elif find_1 == -1:\n",
    "                            result_list.append([news_title])\n",
    "                    except:\n",
    "                        error_cnt += 1\n",
    "\n",
    "naver_news_title(date_0)\n",
    "title_df_2 = pd.DataFrame(result_list, columns=['뉴스제목'])\n",
    "title_df_2['주가변동'] = 0\n",
    "result_list = []\n",
    "\n",
    "naver_news_title(date_1)\n",
    "title_df_3 = pd.DataFrame(result_list, columns=['뉴스제목'])\n",
    "title_df_3['주가변동'] = 1\n",
    "result_list = []\n",
    "\n",
    "#네이버 크롤링 데이터 합쳐 csv파일로 만들기\n",
    "title_df2 = pd.concat([title_df_2, title_df_3])\n",
    "#중복 데이터 삭제 \n",
    "del_title_df2 = title_df2.drop_duplicates(['뉴스제목'])\n",
    "title_df2.to_csv('네이버_뉴스타이틀.csv', index=False, encoding='utf-8-sig')\n",
    "title_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>뉴스제목</th>\n",
       "      <th>주가변동</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>슈프리마아이디 및 한국바이오젠 코스닥 상장</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이주열 한은 총재 \"미국 연준, 예상보다 덜 완화적\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>뉴욕증시, 연준 금리 경로 불확실성 속 상승 출발</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>美 실업수당 청구 21만5000건..예상치 상회</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>英 중앙은행, 올해 성장률 1.3%로 하향조정..기준금리는 동결</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12295</th>\n",
       "      <td>29일, 거래소 기관 순매수상위에 운수장비 업종 4종목</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12296</th>\n",
       "      <td>29일, 거래소 외국인 순매수상위에 운수장비 업종 5종목</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12297</th>\n",
       "      <td>기다리던 공매도 대책 나왔는데..개미 반응은 싸늘, 왜?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12298</th>\n",
       "      <td>효성, 2분기 영업익 356억원..전년대비 83.6% 감소</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12299</th>\n",
       "      <td>키움투자자산운용, 히어로즈 글로벌리츠이지스액티브ETF 상장</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      뉴스제목  주가변동\n",
       "0                  슈프리마아이디 및 한국바이오젠 코스닥 상장     0\n",
       "1            이주열 한은 총재 \"미국 연준, 예상보다 덜 완화적\"     0\n",
       "2              뉴욕증시, 연준 금리 경로 불확실성 속 상승 출발     0\n",
       "3               美 실업수당 청구 21만5000건..예상치 상회     0\n",
       "4      英 중앙은행, 올해 성장률 1.3%로 하향조정..기준금리는 동결     0\n",
       "...                                    ...   ...\n",
       "12295       29일, 거래소 기관 순매수상위에 운수장비 업종 4종목     1\n",
       "12296      29일, 거래소 외국인 순매수상위에 운수장비 업종 5종목     1\n",
       "12297      기다리던 공매도 대책 나왔는데..개미 반응은 싸늘, 왜?     1\n",
       "12298     효성, 2분기 영업익 356억원..전년대비 83.6% 감소     1\n",
       "12299     키움투자자산운용, 히어로즈 글로벌리츠이지스액티브ETF 상장     1\n",
       "\n",
       "[22170 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다음 크롤링 함수 daum_news_title\n",
    "result_list = []\n",
    "error_cnt = 0\n",
    "def daum_news_title(dates):\n",
    "    base_url = \"https://news.daum.net/breakingnews/economic/stock?page={1}&regDate={0}\"\n",
    "    headers = {\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'\n",
    "    }\n",
    "    for date in dates:\n",
    "        for page in range(1, 3):\n",
    "            url = base_url.format(date, page)\n",
    "            res = requests.get(url, headers=headers)\n",
    "            if res.status_code == 200:\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                title_list = soup.select('ul.list_news2.list_allnews > li')\n",
    "                for title in title_list:\n",
    "                    try:\n",
    "                        news_title = title.select_one('.link_txt').text.strip()\n",
    "                        find_1=news_title.find(\"[\")\n",
    "                        find_2=news_title.find(\"]\")\n",
    "                        if find_1 != -1:\n",
    "                            slice_news_title=news_title[find_1:find_2+1]\n",
    "                            news_title.strip(slice_news_title)\n",
    "                            result_list.append([news_title.strip(slice_news_title).strip()])\n",
    "                        elif find_1 == -1:\n",
    "                            result_list.append([news_title])\n",
    "                    except:\n",
    "                        error_cnt += 1\n",
    "\n",
    "daum_news_title(date_0)\n",
    "title_df_4 = pd.DataFrame(result_list, columns=['뉴스제목'])\n",
    "title_df_4['주가변동'] = 0\n",
    "result_list = []\n",
    "\n",
    "daum_news_title(date_1)\n",
    "title_df_5 = pd.DataFrame(result_list, columns=['뉴스제목'])\n",
    "title_df_5['주가변동'] = 1\n",
    "result_list = []\n",
    "\n",
    "#다음 크롤링 데이터 합쳐 csv파일로 만들기\n",
    "title_df3 = pd.concat([title_df_4, title_df_5])\n",
    "#중복 데이터 삭제 \n",
    "del_title_df3 = title_df3.drop_duplicates(['뉴스제목'])\n",
    "del_title_df3.to_csv('다음_뉴스타이틀.csv', index=False, encoding='utf-8-sig')\n",
    "del_title_df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#뉴스데이터 하나로 합치기 \n",
    "naver_data = pd.read_csv('네이버_뉴스타이틀.csv')\n",
    "paxnet_data = pd.read_csv('팍스넷_뉴스타이틀.csv')\n",
    "all_title = pd.concat([naver_data, paxnet_data])\n",
    "all_title.to_csv('paxnet_naver.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
